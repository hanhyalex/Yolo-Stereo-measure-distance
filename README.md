使用介绍：



本软件是为了完成我的毕业设计所制作，之所以放到这里是为了推进一下自己的进度，以及做一下使用方法说明，如果有人想拿去发论文也可以，毕竟开源就是为了分享知识，共同进步。


本文首先介绍软件作用，然后介绍使用方法


**软件作用：**


目前的版本可以做到对玉米苗的识别与距离测量，当然如果你做一点很微小的改动，就可以实现对任意物体的识别与距离测量，在机器视觉领域可以说是应用性极强，可以完成多种题目的论文。

第一部分：物体识别部分


此部分根据基于tensorflow1.x实现的yolo完成（[https://github.com/qqwweee/keras-yolo3.git](https://github.com/qqwweee/keras-yolo3.git)），如果想识别某几种特定的物体就需要自行对yolo进行训练，生成对应的.weight文件，放置在指定目录下即可完成，对后续的测距环节没有影响

![](https://raw.githubusercontent.com/hanhyalex/pics/main/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201219163747.png)

第二部分：测距部分


此部分使用opencv自带的SGBM程序完成，在对双目相机标定后可以实现极为精确的距离输出

![](https://raw.githubusercontent.com/hanhyalex/pics/main/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201219163840.png)

第三部分：GUI设计

由于前文程序全部使用python完成，所以为了方便，此部分也使用python的pyqt包进行窗口设计，主题代码是从CSDN文章中找的，然后对其中的按钮进行了重写，使得可以完成特定的任务



![](https://raw.githubusercontent.com/hanhyalex/pics/main/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201219164447.png)


![](https://raw.githubusercontent.com/hanhyalex/pics/main/%E5%BE%AE%E4%BF%A1%E6%88%AA%E5%9B%BE_20201219164422.png)

**使用方法**


进入gui，点击选择图片，弹出文件选择器，选择双目相机拍摄的左图，完成后会再次弹出文件选择器，再次选择右图即可完成图片选择。在gui的图形框中会出现最终的图片



**代码结构介绍**


1.yolo结构

权重文件存储地址：keras-yolo3-master\model_data

训练方法详见
[https://github.com/qqwweee/keras-yolo3.git](https://github.com/qqwweee/keras-yolo3.git)

训练后把对应的classes文件以及.weight文件和.cfh文件复制过来，YOLO部分就自定义完成了


2.SGBM结构

SGBM定义在my_yolo.py中的yolo_my_img函数中，如果要自己定义模型的话需要修改**标定数据**，**SGBM参数**，以及一些被我垃圾代码写死的绝对路径，使得你的测距部分更为精确


3.测距后处理

其实这个部分是最为困难和可以改进的，每一种物体都有自己的结构，比如汽车与你的距离，你可能会测到车玻璃，车胎，车门，到底哪个是与你车的距离呢，你可能说肯定是车离你最近的点啊，但是你的yolo算法会把包括车的所有部分都算进去，那么怎么才能把最近的点找出来呢。这只是一种情况，比如在我的项目中，要测玉米根茎与我的距离，那么玉米叶和玉米根茎肯定距离不一样啊，你怎么精确定位到玉米根茎呢，为了解决这个问题暂时选用了权衡只计，就是画出直方图，然后对直方图进行操作，找到折中的距离暂时糊弄过去，但这不是最优之策，同样的，这里也是创新点出现的地方，想出你的目标到底应该怎么测。

4.重新画框

可能对很多论文来说最后一步才是最重要的，因为你论文中的图片就要用到这个部分进行图片的输出，那么图片一定要精确地显示距离（即使算法不准，你也可以自己修改）

5.测试代码

在主目录下的test_yolo.py是测试代码的位置，这里可以将my_yolo中的代码复制过来，然后直接写在主函数内部，这样就可以在spyder的控制台中看到你的变量和图形输出，对后续调试，改进起到加速的作用



**下一步的工作**

1.解决距离如何测算的更加精准 //与导师交流中


2.代码格式规范化 //如果真的有人用的话才会进行修改。。。






